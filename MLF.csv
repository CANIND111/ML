x,y
Baseline,"numfeatures = ['bathrooms', 'bedrooms', 'longitude', 'latitude'] X = rent_clean[numfeatures] y = rent_clean['price'] 
rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True) rf.fit(X, y)  oob_baseline = rf.oob_score_ print(f""Out-of-bag R^2 for baseline model is: {oob_baseline}"")"
R2,"R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}this tells us that: - $R^2 = 1$ means our model is perfect; 
- $R^2 \approx 0$ means our model does no better than just predicting the average; - $R^2 \lt\lt 0$ means our model does worse than predicting the average."
evaluate function ,"from rfpimp import * def evaluate(X, y):     rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True)     rf.fit(X, y)
    oob = rf.oob_score_     n = rfnnodes(rf)     h = np.median(rfmaxdepths(rf))      print(f""OOB R^2 is {oob:.5f} using {n:,d} tree nodes with {h} median tree depth"")    return rf, oob  ///"
evaluate new ulti,"def evaluate(X, y, n_estimators=50):     rf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=-1, oob_score=True)     rf.fit(X, y)
    oob = rf.oob_score_     n = rfnnodes(rf)     h = np.median(rfmaxdepths(rf))     print(f""OOB R^2 is {oob:.5f} using {n:,d} tree nodes with {h} median tree depth"")     return rf, oob"
Show importances new ulti ,"def showimp(rf, X, y):     features = list(X.columns)      I = importances(rf, X, y, features=features)     plot_importances(I, color='#4575b4')"
show import,"def showimp(rf, X, y):     features = list(X.columns)     features.remove('latitude')     features.remove('longitude')     features += [['latitude','longitude']]     I = importances(rf, X, y, features=features)    plot_importances(I, color='#4575b4') /// features = list(X.columns)
features / evaluate(X, y) / showimp(rf, X, y)"
permutation,"def perm_importances(X, y):     rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True, random_state=999)    rf.fit(X, y     r2 = rf.oob_score_     print(f""Baseline R^2 with no columns permuted: {r2:.5f}\n"")     for col in X.columns:         X_col = X. copy()         _col[col] = X_col[col].sample(frac=1).values         rf.fit(X_col, y)         r2_col = rf.oob_score_         print(f""Permuting column {col}: new R^2 is {r2_col:.5f} and difference from baseline is {r2 - r2_col:.5f}"")  / perm_importances(X, y)"
drop importances,"def drop_importances(X, y):     rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True, random_state=999)     rf.fit(X, y)     r2 = rf.oob_score_     print(f""Baseline R^2 with no columns dropped: {r2:.5f}\n"")     for col in X.columns:         X_col = X.copy()         X_col = X_col.drop(col, axis=1)          rf.fit(X_col, y)         r2_col = rf.oob_score_         print(f""Dropping column {col}: new R^2 is {r2_col:.5f} and difference from baseline is {r2 - r2_col:.5f}"") / drop_importances(X, y)"
correlation,"X_dup = X.copy() X_dup['bedrooms_dup'] = X_dup['bedrooms'] X_dup.head() / drop_importances(X_dup, y) / braking corr … noise = np.random.normal(0, 2, X_dup.shape[0]) 
X_dup['bedrooms_dup'] = X_dup['bedrooms'] + noise X_dup.head() / drop_importances(X_dup, y)"
dfnum dfnonum ,"num_df = df.select_dtypes(include=['int', 'float']) / cat_df = df.select_dtypes(include=['object'])

"
encoders 1 low mediun high Ordinal encoder ,"first call feature.unique  rent_clean['interest_level'].unique() --- pip install category_encoders / X = rent_clean[numfeatures + ['interest_level']] X.head() /// import category_encoders as ce encoder = ce.OrdinalEncoder(mapping = [{'col':'interest_level','mapping':{'low' : 1 , 'medium' :2, 'high':3}}]) encoder.fit(X) X = encoder.transform(X)  X.head() / rf, oob = evaluate(X, y) / showimp(rf, X, y)"
Encoder manager id ordinal withou mapping / count encoder/ one hot encoder,"rent_nonnum['manager_id'].unique() / X = rent_clean[numfeatures + ['manager_id']] X.head() / encoder = ce.OrdinalEncoder(cols=['manager_id']) encoder.fit(X) X = encoder.transform(X) X.head()  /// COUNT encoder = ce.CountEncoder(cols=['manager_id']) encoder.fit(X) X = encoder.transform(X)  X.head() / rf, oob = evaluate(X, y) / showimp(rf, X, y) /// encoder = ce.OneHotEncoder(cols=['manager_id']) encoder.fit(X) X = encoder.transform(X) X.head()"
"new df drop na, lower case , lambda","rent_text = rent_clean[['description','features','photos']].copy() rent_text.head() / rent_clean['description'] = rent_clean['description'].fillna('') rent_clean['description'] =  rent_clean['description'].str.lower() rent_clean['description'].head(50) // rent_clean['features'] =  rent_clean['features'].str.lower()  rent_clean['doorman'] =  rent_clean['features'].str.contains(""doorman"")
rent_clean['hardwood'] =  rent_clean['features'].str.contains(""hardwood"")  rent_clean.head().T / rent_clean['photos'].apply(lambda x: len(x.split("",""))) / rent_clean['num_photos'] = rent_clean['photos'].apply(lambda x: len(x.split("","")))"
adding features ,"rent_clean['renov'] =  rent_clean['description'].str.contains(""renov"") rent_clean['new'] =  rent_clean['description'].str.contains(""new"") rent_clean.head().T"
more info function sniff mod ,"def sniff_modified(df):        info = pd.DataFrame()     info['data type'] = df.dtypes     info['percent missing'] = df.isnull().sum()/len(df) *100
    info['No. unique'] = df.apply(lambda x: x.nunique())     info['unique values'] = df.apply(lambda x: x.unique())     return info.sort_values('data type') / sniff_modified(df)"
missing data fill with 0,"basefeatures = ['SalesID', 'MachineID','ModelID','datasource','YearMade','auctioneerID','MachineHoursCurrentMeter']  X = df[basefeatures] y = df['SalePrice'] X = X.fillna(0)  // sample df = df.iloc[-100000:] / rf , oob = evaluate(X, y, n_estimators=100) / showimp(rf,X,y)"
clean up data,"df.drop(['SalesID', 'MachineID'], axis=1, inplace=True) df.columns / df['auctioneerID'] = df['auctioneerID'].astype(str) / "
normalize string functions ,"from pandas.api.types import is_object_dtype,is_string_dtype def df_normalize_string(df):     for col in df.columns:         if is_object_dtype(df[col]) or is_string_dtype(df[col]):             df[col] = df[col].str.lower()             df[col] = df[col].fillna(np.nan)              df[col] = df[col].replace('none or unspecified', np.nan)              df[col] = df[col].replace('none', np.nan)             df[col] = df[col].replace('#name?', np.nan)             df[col] = df[col].replace('', np.nan)  /// df_normalize_string(df)"
"extract size '39 inch"" just the number ","def extract_size(df, colname):     df[colname] = df[colname].str.extract('(\d+\.\d+|\d+)' , expand=True)     df[colname] = df[colname].replace('',np.nan)     df[colname] = pd.to_numeric(df[colname]) / extract_size(df, 'Tire_Size')"
parse length pasar pulgadas a inches,"def parse_length(length):     if pd.isnull(length):         return np.nan     else:         feet, inches = length.split(""' "")         feet = float(feet)         inches = float(inches.replace(""\"""",""""))         return (12*feet) + inches // df['Stick_Length'] = df['Stick_Length'].apply(lambda x:parse_length(x))  // llamar sniff_modified(df)"
Handling cat data cat.codes strig to cat / cat to code,"df[""Hydraulics_Flow""] = df[""Hydraulics_Flow""].astype(""category"").cat.as_ordered() df[""Hydraulics_Flow""].unique() // f[""Hydraulics_Flow""] = df[""Hydraulics_Flow""].cat.codes + 1 df[""Hydraulics_Flow""].unique() ---> result 0,2,1 zero means nan //// from pandas.api.types import is_categorical_dtype, is_object_dtype / def df_string_to_category(df):     for col in df.columns:         if is_object_dtype(df[col]):              df[col] = df[col].astype(""category"").cat.as_ordered()       /  def df_category_to_code(df):     for col in df.columns:         if is_categorical_dtype(df[col]):              df[col] = df[col].cat.codes + 1   // df_string_to_category(df) // df_category_to_code(df) // sniff_modified(df)"
fixing num var ,"def fix_missing_num(df,colname):     df[colname+'_na'] = pd.isnull(df[colname])     df[colname].fillna(df[colname].median(), inplace=True) // df.loc[df.eval(""MachineHoursCurrentMeter==0""),""MachineHoursCurrentMeter""] = np.nan / df.loc[df.YearMade < 1950, ""YearMade""] = np.nan / df.loc[df.eval(""saledate.dt.year < YearMade""), ""YearMade"" ] = df['saledate'].dt.year / sniff_modified(df) / create a new model"
split dates,"def df_split_dates(df,colname):     df[""saleyear""] = df[colname].dt.year     df[""salemonth""] = df[colname].dt.month     df[""saleday""] = df[colname].dt.day     df[""saledayofweek""] = df[colname].dt.dayofweek     df[""saledayofyear""] = df[colname].dt.dayofyear     df[colname] = df[colname].astype(np.int64) // df_split_dates(df,'saledate') / df['age'] = df['saleyear'] - df['YearMade']"
ordinal encode,"df_raw['ProductSize'].unique() / sizes = {None:0, 'Mini':1, 'Compact':1, 'Small':2, 'Medium':3, 'Large / Medium':4, 'Large':5} df['ProductSize'] = df_raw['ProductSize'].map(sizes).values df['ProductSize'].unique() / X = df.drop('SalePrice', axis=1) y = df['SalePrice'] rf, oob_psize = evaluate(X, y, n_estimators=150)"
one hot encoding get dummies,"df['Hydraulics_Flow'] = df_raw['Hydraulics_Flow'].values   df['Hydraulics_Flow'] = df['Hydraulics_Flow'].replace('None or Unspecified', np.nan)   df['Hydraulics_Flow'].unique() // onehot = pd.get_dummies(df['Hydraulics_Flow'], prefix='Hydraulics_Flow', dtype=bool) onehot.head(3) // del df['Hydraulics_Flow'] df = pd.concat([df, onehot], axis=1)  /// SECOND VAR df['Enclosure'] = df_raw['Enclosure'].values df['Enclosure'] = df['Enclosure'].replace('EROPS w AC', 'EROPS AC') #df['Enclosure'] = df['Enclosure'].replace('None or Unspecified', np.nan)  onehot = pd.get_dummies(df['Enclosure'], prefix='Enclosure', dtype=bool) onehot.head(3) / del df['Enclosure'] df = pd.concat([df, onehot], axis=1) df.head(3).T  //. EVAL NUE MODEL X = df.drop('SalePrice', axis=1)
y = df['SalePrice'] rf, oob_one_hot = evaluate(X, y, n_estimators=150)"
log of the price,"df['SalePrice'].hist() / np.log(df['SalePrice']).hist() / X = df.drop('SalePrice', axis=1) y = df['SalePrice'] log_y = np.log(y) rf, oob_log = evaluate(X, log_y, n_estimators=150)"
result change percentage ,"print(f""{round(100 * ((1 - 0.903) - (1 - 0.919)) / (1 - 0.903))}%"")"
